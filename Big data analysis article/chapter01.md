# 1. 빅데이터 분석 기회
## 1.1 빅데이터의 이해
* 데이터: 관찰이나 측정을 통해 수집된 단순 사실이나 결과값, 가치가 없다
* 정보: 데이터를 가공하여 판단의 근거로 사용하기 위해 의미 가치를 부여한 것, 가치가 있다

데이터<정보<지식<지혜

#### 빅데이터: 대량의 데이터 이상의 정형 또는 비정형 데이터, 가치를 추출하고 분석하는 기술
특징:규모(volume),가치,신뢰성(Veracity),시각화,다양성,휘발성(Volatility),속도,정확성

유형
- 정형: 스키마, DBMS에서 저장될 수 있는 구조 / 관계형 데이터베이스
- 반정형: 메타 정보 포함된 구조, 메타데이터나 데이터 스키마 정보를 포함하는 데이터 / XML HTML JSON
- 비정형: 고정 필드 및 메타데이터가 정의되지 않음, 수집을 위해서는 Crawler, API, RSS등 기술 활용 / 텍스트문서,이미지,동영상

데이터 수집 기술
- 크롤링: 외부 데이터 수집 방법으로 인터넷에서 제공되는 웹문서 정보 수집
- Open APl: 웹 운영주체가 정보 및 데이터를 개발자와 사용자에게 공개하는 수집
- Streaming: 다양한 IoT 센서, CCTV 등 연속적으로 발생하는 데이터를 실시간 수집

#### 인공지능: 사고나 학습 등 인간이 가진 지적 능력을 컴퓨터를 통해 구현하는 기술
딥러닝<머신러닝<인공지능

머신러닝
- 지도학습: 레이블 있음
- 비지도학습: 레이블 없음
- 강화학습: 선택 가능한 행동들 중 보상을 최대화하는 행동을 학습시키면서 스스로 올바른 선택을 하는 알고리즘

## 1.2 데이터 분석 계획
하향식 접근방식
- 분석과제가 정해져 있고 해법을 찾기위해
- 문제 탐색-정의-해결방안 탐색-타당성 검토-선택

상향식 접근방식
- 하향식 접근법의 한계를 극복
- 데이터를 기반으로 문제를 지속적으로 개선
- 비지도학습, 프로토타이핑 접근법

분석과제 도출 유형
- 최적화: 분석대상ㅇ,분석방법ㅇ
- 솔루션: 분석대상ㅇ,분석방법x
- 통찰: 분석대상x,분석방법ㅇ
- 발견: 분석대상x,분석방법x

단계>태스크>스텝

#### 빅데이터 분석 방법론
1. KDD
- Fayyad 프로파일링 기술로 개발
- 데이터 세트 선택,데이터 전처리,데이터 변환,데이터 마이닝, 데이터 마이닝 결과 평가

2. CRISP-DM
- 유럽연합에서 시작, 현재는 중단
- 업무 이해, 데이터 이해, 데이터 준비, 모델링, 평가, 전개

3. SEMMA
- SAS사가 주도
- 샘플링, 탐색, 수정, 모델링, 검증


WBS: 프로젝트 관리 및 시스템 엔지니어링에서 프로젝트를 소규모의 구성 단위까지 나누어 전달하는 기능

## 1.3 데이터 수집 및 저장 계획
내부 데이터
- 조직 내부에 위치
- 수집 용이한 정형
- 서비스: SCM(supply chain Management), ERP(Enterprise Resoruce Planning), CRM(Customer Relationship Management)
- 네트워크: 방화벽, 스위치, IPS, IDS
- 마켓팅: 고객 포털 시스템


외부 데이터
- 공공 데이터의 경우 Open API 또는 파일을 통해 수집
- 수집 어려운 비정형 데이터
- 소셜: SNS, 커뮤니티
- 네트워크: 센서 데이터, 장비 간 발생 로그

#### 정형 데이터 수집 방식 및 기술
1. ETL:DW(data warehouse)및 DM(data mart)으로 이동시키기 위해 필요한 원본 데이터를 추출 변환해 적재하는 기술
- 추출(Extract): DB로부터 데이터 추출, JDBC ODBC 활용
- 변환(Transform): 적절한 포맷이나 구조로 데이터 저장하기 위해 변환, 데이터 결합/통합, 데이터 표준화 수행
- 적재(Load): 추출 및 변환 데이터를 최종 대상에 저장, insert delete update append 수행

2. FTP(File Transfer Protocol): TCP/IP 기반으로 서버 클라이언트에서 파일 송수신을 하기 위한 프로토콜
- Active FTP: 서버가 자신의 포트를 통해 클라이언트로 데이터 전송하는 방식, 명령 21, 데이터 20
- Passive FTP: 클라이언트가 서버로 접속해 데이터 가져가는 방식, 명령 21, 데이터 1024 이후

3. 스쿱(Sqoop): MYSQL, Oracle 같은 관계형 데이터베이스 시스템에서 하둡 파일 시스템으로 데이터를 수집하거나, 하둡에서 관계형으로 데이터 전송
- 병렬 데이터 전송
- 한 번에 전송 가능한 벌크 임포트 지원

4. API: 시스템 간 연동을 통해 실시간으로 데이터를 수신

#### 비정형 데이터 수집 방식 및 기술
스크래파이와 아파치 카프카의 활용 증가 추세
1. 크롤링: 웹 문서 및 콘텐츠 수집 기술
2. RSS: 
3. Open API: api로 데이터 수집
4. 스크래파이: 웹 사이트 크롤링해 구조화된 데이터 수집
  - 파이썬 기반
  - 단순 스크랩 과정
  - 다양한 부가 요소
  - 주요기능: Spider Selector Items Pipelines

5. 아파치 카프카: 레코드 스트림을 발행,구독하는 방식의 분산 스트리밍 플랫폼 기술
- 신뢰성, 확장성 제공
- 주요기능: 소스 채널 싱크 인터프리터

#### 반정형 데이터 수집 방식 및 기술
플럼, 스크라이브, 척와의 활용이 점차 증가 추세
1. 센싱: 센서로부터 수집 및 데이터를 네트워크를 통해 수집
2. 스트리밍: 네트워크 통해 미디어 데이터를 실시간으로 수집
3. 플럼: 스트리밍 데이터 흐름을 비동기 방식으로 처리하는 분산형 로그 수집 기술
- 이벤트와 에이전트 활용 기술
- 특징: 발생/구독 모델, 고가용성, 파일 기반 저장방식
- 주요기능: 소스, 채널, 싱크

4. 스크라이브: 스트리밍되는 로그 데이터를 수집해 분산 시스템에 데이터를 저장하는 대용량 실시간 로그 수집 기술
- 단일 중앙 스크라이브 + 다수의 로컬 스크라이브
- 특징: 실시간 스트리밍 수집, 확장, 데이터 수집의 다양성, 고가용성

5. 척와: 에이전트와 컬렉터 구성으로 데이터 수집, 데이터를 하둡 파일 시스템에 저장하는 데이터 수집 기술
- 특징: HDFS 연동,  실시간 분석 제공, 청크 단위 처리
- 구성: 에이전트+컬렉터
- 데이터 처리: 아카이빙, 디먹스

#### 데이터 유형
- 정형 데이터: 스키마 구조, 고정된 필드에 저장 / 관계형 데이터베이스<br>
- 반정형 데이터: 스키마 구조, 메타데이터 포함, 일관성x / XML, HTML, JSON, RSS<br>
- 비정형 데이터: 스키마 구조X, 고정된 필드에 저장x / sns, 웹 게시판<br>

- 실시간 데이터<br>
- 비실시간 데이터

- 파일 데이터<br>
- 데이터베이스 데이터<br>
- 콘텐츠 데이터<br>
- 스트림 데이터

- 정성적 데이터: 언어, 문자<br>
- 정량적 데이터: 수치, 도형

#### 데이터 속성
수치형 변수: 몇 개, 연산 가능
- 비율 척도: 연산했을 때 의미가 있음, 절대 영점 존재

범주형 변수: 범주로 구분해 측정된 변수, 연산 의미 없음
- 명목 척도: 임의의 범주로 분류한 후 기호나 숫자를 부여, 분류의 수치화
- 서열 척도: 서열의 순서화
- 등간 척도

#### 데이터 변환 기술
1. 평활화: 잡음 제거위해 추세에 벗어나는 값 변환
2. 집계:
3. 일반화: 특정 구간에 분포하는 값으로 스케일 변환
4. 정규화: 데이터를 정해진 구간 내에 들도록 하는 기법
5. 속성 생성: 데이터 통합 위해 새로운 속성이나 특징 만드는 방법

#### 데이터 비식별화 처리 기법
1. 가명처리: 다른 값으로 대체 / 성명
2. 총계처리: 통곗값을 적용해 특정 개인을 판단할 수 없게 하는 기법 / 생일, 신체정보
3. 데이터값 삭제: 특정 데이터값 삭제 / 이름, 전화번호, 주민번호
4. 범주화: 해당 그룹의 대푯값으로 변환 / 주소, 주민번호
5. 데이터 마스킹: 전체 또는 부분적으로 대체 값으로 변환 / 이름, 전화번호, 주민번호

