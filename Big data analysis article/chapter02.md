# 2. 빅데이터 탐색
## 2.1 데이터 전처리
데이터 전처리>데이터 정제,분석 변수처리

### (1) 데이터 정제: raw data의 결측값, 이상값, 잡음 등을 찾아내 조치를 취하는 것
Raw data -> structure data -> data processing -> EDA

- EDA(탐색적 데이터 분석): 데이터 모델링 전 수집된 데이터 분포 파악, 모델링에 사용할 수 있는지 data인지 파악
- 데이터 전처리: 정제 가공 변환을 거쳐서 모델링에 필요한 변수로 만듦

### (2) 데이터 결측값 처리
#### 결측값
- MCAR 완전 무작위 결측: 결측값이 변수들과 상관없이 발생, 전산오류
- MAR 무작위 결측: 결측치가 특정 변수와 연관 있지만 전체 결과에는 영향이 없다
- NMAR 비무작위 결측: 누락된 값이 다른 변수와 연관 있는 경우

#### 처리
1. 삭제(주로 MCAR)
- 단일값 삭제, 특정값 삭제(샘플축소문제)
2. 대체
- 특정값 대체: 평균값 대체, 회귀, hot-deck(연구중인 자료 이용), cold-deck(외부 자료 이용)
- 다중값 대체: simple imputation을 여러번 반복해서 확률적 대체
- 단순 확률 대체법: 적절한 확률을 반영, ex) 이웃대체법: 범주형일 경우 가까운 데이터 중 최빈값, 연속형이면 이웃데이터의 중앙값으로 대체

### (3) 데이터 이상값 처리
#### 이상값: 소수라도 결과에 큰 영향을 줌

#### 이상값 탐지
1. 통계적 기법
- ESD: 평균에서 좌우로 3시그마
- 기하평균: 기하평균에서 좌우로 2.5시그마
- 4분위 편차: Q1-1.5 x IQR ~ Q3+1.5 x IQR 벗어나면 이상치
2. 시각화: 차트로 탐지, 히스토그램, 확률밀도함수, box plot
3. 알고리즘: 군집, 마할라노비스 거리, LOF, iForest

#### 처리
- 제거: 모두 제거, 데이터 많고 이상값 적을때 적합
- 대체: 하한값, 상한값으로 이상값 대체, 평균이나 중앙값으로 대체
- 변환: 데이터 전체에 로그 혹은 제곱근을 취해 범위가 줄어들도록 변환

### (1) 변수선택: 독립변수 중 종속변수에 가장 영향 있을 만한 변수만을 선정, 독립변수가 많을수록 종속변수 예측 가능성 UP
1. filter: 독립변수,종속변수 하나씩 통계적 기법을 이용해 상관이 있는 변수 찾기
- 관련 없는 변수 거르기
- 상관이 있는것만 변수로 투입
- x**2검정, 상관관계분석, t-test

2. wrapper: 독립변수 미리 정해놓고 예측 과정에서 예측과 분류에 기여하는 영향 변수만 선정
- 비용, 시간 up 정확도 Good
- 회귀분석 알고리즘에서 독립변수 중 유의미한 영향을 미치는 변수군만 찾아냄
- 전진방법(기여하는것 부터 투입),후진방식(무의미 제거), 단계선택법(두 과정 반복)

3. Embedded: 모델링 기법 자체에 변수선택 방법이 포함
- 라소회귀분석: 가중치의 절댓값의 합을 최소화하는 제약조건, L1-norm
- 릿지회귀: 가중치들의 제곱 합을 최소화하는 제약조건, L2-norm 
- 엘라스틱넥: 가중치 절댓값의 합과 제곱 합을 동시 제약조건

### (2) 차원축소: 변수의 정보를 최대한 유지하면서 개수를 줄이는 방법
1. 주성분 분석: 고차원 공간의 표본을 저차원 공간으로 변환, 정방행렬에서만 사용
2. 요인분석: 데이터 안의 구조 해석, 설문조사에서 활용
3. 독립성분분석: 비정규 분포를 따르는 차원축소 기법
4. 다차원 척도법: 유사성을 측정해 2,3차원 공간상에 점으로 표현
5. t-SNE: 지역 인접성을 보존하려고 시도하는 차원축소 알고리즘
6. 특이값 분해: 행렬데이터에서 특이값 추출하고 축약

장점: 데이터 양 줄어 분석시간 준다. 학습모델이 간단해진다.

### (3) 파생변수 생성: 기존 변수들을 이용해 새롭게 만든 변수

### (4) 변수변환: 한 변수로 새로운 한 변수를 만든다
1. 구간화: 연속형 변수를 범주화
2. 단위 변환: 로그, 제곱근으로 변환
3. 정규화: 독립변수의 단위를 동일하게 하는 방법
- Min-Max Scaling: 대표적인 스케일링 방법, (x-xmin)/(xmax-xmin), 양의 값 가짐 
- standardization: 수치와 평균의 차이를 표준편차로 나눈 값
4. 더미변수화: 범주형 자료의 숫자를 0과 1로 변경
- 통계에서 더미변수, 머신러닝에서 원핫인코딩

### (5) 불균형 데이터 처리: 환자 500명, 정상 9500명 차이가 커서 모델링 어렵다
1. 과소표집: 정상인 9500명에서 500명 추출
- 랜덤 언더 샘플링
- 토멕 링크 방법: 다수 클래스에 속한 토멕링크(경계선 가까이 있는 데이터) 제거
- CNN: 밀집된 데이터 제거, 대표적인 데이터만 남김
- OSS: 토멕 링크 + CNN
2. 과대표집: 환자 500을 정상 9500 가량으로 증가
- 랜덤 오버 샘플링
- SMOTE
- Borderline-SMOTE
- ADASYN

## 2.2 데이터 탐색
### (1) 데이터 탐색 개요
정상적인 범위 내에 있는가?
- 성별 1(남), 2(여)인데 3 입력되면 안됨
- 콜레스테롤 수치 0~240인데 500이면 안됨
- 히스토크램, 상자도표로 탐색

분포가 너무 한쪽으로 쏠리지 않았는가?
- 중심에 자료 많고 양끝으로 줄어드는 모양이 좋음
- 정규분포

경향성에서 크게 벗어난 값이 있는가?
- 산점도, 상관관계분석, 교차분석등으로 변수간 기초분석
### (2) 상관관계 분석
### (3) 기초통계량 추출 및 이해
#### 중심화 경향
1. 평균
- 산술평균: 자료를 모두 더해 총 개수로 나눈 값
- 기하평균: 비율(성장률, 상승률)의 평균을 구할때 이용, 모든 수를 100을 기준으로 곱해 n 제곱근을 씌움
- 조화평균: 시간당 변하는 값, 속도,시세 등의 평균을 산출하는데 이용, 역수의 합을 1/자료수로 곱한 후 역수를 취한 값
2. 중위수: 중앙값, 정렬했을때 위치가 중앙(50%)에 위치한 값
3. 최빈값: 가장 자주 나타나는 값
#### 산포도
1. 범위: 최대값과 최소값의 차이로 계산
2. 사분위편차: 정렬된 자료에서 상위 25%와 하위 25% 간의 차이로 계산
3. 평균편차: (x-abs(x))/n
4. 분산: (x-abs(x))**2/n-1
5. 표준편차: 분산에 루트 씌운값, 활용도 높음
#### 분포도
1. 왜도: 분포가 기울어진 방향과 정도를 나타내는 양, 중심이 왼쪽에 있으면 양수 값
2. 첨도: 분포가 얼마나 중심에 집중되어 있는가, 중심이 얼마나 뾰족한가

상관관계 분석
1. Pearson: 연속형일 경우
2. Spearman: 서열자료일 경우
3. Kendall: 서열자료이며 순위의 일치도까지 파악

공분산: 평균으로부터 두 변수가 얼마나 같이 떨어져 있는가

### (4) 시각적 데이터 탐색
#### 범주형 자료 시각적 탐색
1. 원그래프
2. 막대 그래프
3. 꺾은선 그래프

#### 연속형 자료 시작적 탐색
1. 히스토그램
2. 상자-수염도표: 중위수, 최대값, 최소값, 사분위수 이용해 표현
3. 도수곡선

#### 두 변수간 관계의 시각적 탐색
1. 산점도
2. Correlogram: 상관관계를 그래프로 표현

### 시공간 데이터 탐색
- 시간에 따라 위치 변하는 데이터
- 이산적 변화: 주기가 일정하지 않은 데이터를 이용해 표현
- 연속적 변화: 일정한 주기로 수집되는 데이터를 이용
- 시계열 그래프, 모션 차트

공간 데이터
- 공간상의 객체, 사건을 기록한 데이터
- 시각화 도구: Arc GIS, Power Map
- 코로플레스 지도, 카토그램, 버블 플롯맵

포인트: 하나의 노드
라인: 두 포인트를 잇는 선
폴리곤: 라인으로 구성된 다각형
폴리라인: 폴리곤을 형성하는 다각선

### 다변량 데이터 탐색
일변량
- 단일 변수에 대한 진단 및 분석
- 기술통계분석, 히스토그램, 박스 플롯으로 자료의 중심, 퍼짐정도, 왜도 및 첨도 살펴봄
- 이상치, 결측지 파악

이변량
- 두개의 변수에 대한 자료
- 상관관계, 교차분석
- 선형적, 비선형적 관계인지 검토

다변량
- 여러 변수를 고려
- 차원축소: 변수를 축약, 소득 높을수록 저축 증가하는 경향 있다면 하나로 설명할수있는 새로운 축을 만든다.
- 분류: 저축과 소득이 독립변수, 주택소유여부가 종속변수라면 주택소유자와 미소유자를 분류하는 선,곡선의 함수를 찾아야 함
- 회귀: 레이블이 연속형인 경우

### 비정형 데이터 탐색
이미지, 영상, 텍스트(sns 실시간 대화, 이메일 내용), 로그파일처럼 구조화 되지 않은 데이터
1. 텍스트마이닝
- 기초적인 정보 추출, 연관관계 분석, 군집화 기법 적용해 숨겨진 의미 발견
- 텍스트를 정형화 데이터로 변환해서 패턴 
2. 웹 마이닝
- 연결 구조를 가진 데이터에 대한 탐색과 분석 목적
3. 오피니언 마이닝
- 이슈나 인물에 대해 의견 평가 감정등 주관적 정보를 식별해 추출
- 긍정, 부정, 중립인지 분류 혹은 평점을 부여해 정령화하는 과정 요구
- 기업 이미지, 제품 브랜드에 대한 의견 모니터링, 키워드 분석, 감성 분석 사용 

## 2.3 통계기법 이해
### 데이터 요약
자료를 요약,정리함으로써 의미와 가치가 부여됨

통계학의 목적
1. 자료를 정리, 요약함으로써 정보를 쉽게 이해하고 어떤 함의 도출 및 방향 설정/ 기술통계(조사대상 특성을 기술)
2. 전체를 추정하기 위해서 일부만 조사해 모집단의 특성을 알아내기 위함/ 추론통계(모집단 특성 일반화)

전수조사: 모집단을 전부 조사<br>
표본조사: 모집단의 일부만 조사<br>
모집단: 조사 대상인 전체 집간<br>
표본: 모집단에서 일부 표집한 조사 대상<br>
모수: 모집단으로부터 계산된 모든 값

### 표본추출
1. 확률표본추출법
- 모든 추출단위에 대해 사전에 추출확률이 주어짐
- 정부가 수행하는 인구조사, 유권자조사만 가능
- (1) 단순임의추출법
- (2) 계통추출법
- (3) 층화임의추출법
- (4) 집락추출법
- (5) 다단계추출법
- (6) 확률비례 집락추출법

2. 비확률표본추출법
- 표본추출에 조사자의 주관이 개입돼 분석된 결론을 모집단으로 일반화 할 수 없다
- 간편하고 경제적이다
- (1) 편의추출법
- (2) 판단추출법
- (3) 할당추출법

#### 오차
1. 표본추출오차: 표집조사로 인한 오차
2. 비표본추출오차: 표집오차를 제외한 다른 모든 유형의 오차

#### 확률분포
용어정리

시행: 같은 조건 아래에서 반복할 수 있는 실험<br>
사건: 시행에 의해 생기는 여러 결과<br>
단순사건: 한개의 원소로 이루어짐<br>
배반사건: 동시에 나타날 수 없는 관계<br>
독립사건: 발생된 사건이 다음 사건의 확률에 영향x<br>
종속사건: 다음 사건에 영향o<br>
복원추출: 선택된 것을 표본에 넣고 재추출<br>
비복원추출: 선택된 것을 표본에 넣지않고 추출<br>

이산확률분포
1. 이항분포
- 상호 배반적인 사건만 나타나는 경우 / 동전던지기(앞,뒤), 안타칠 가능성(안타,아웃) 
- 분산: npq

2. 포아송분포
- 일정한 시간, 거리에서 드물게 발생하는 확률을 계산할때 기준
- ex) 하루동안 공장에서 나온 불량품 개수

3 .초기하분포
- 

연속확률분포
1. 정규분포
2. 표준정규분포
3. 카이제곱분포
4. t-분포
5. f-분포

### 점추정: 일부 표본을 조사해 전체 모집단을 가늠
ex) 100명 조사 월 평균 문화생활비 100만원 -> 서울시 성인 1000만명 월 평균 문화생활비도 12만원이라고 추정
#### 모평균
- 표본의 평균을 모집단의 평균이라고 추정
- 표본의 분산을 모집단의 분산이라고 추정
- 표본의 표준편차를 모집단의 표준편차라고 추정

#### 모비율
- 표본의 비율을 모집단의 비율이라고 추정
- 표본의 분산을 모집단의 분산이라고 추정, pq/n, 자료의 퍼짐정도, 의견이 반반일때 분산이 가장 큼
- 표본의 표준편차를 모집단의 표준편차라고 추정, root pq/n

### 구간추정: 오차를 고려해 특정한 하나의 값이 다르게 나타날 수 있는 범위까지 추정
신뢰도 95%: 조사 100번 중 95번은 모집단의 평균에 포함된다<br>
구간추정=u(평균) +- z(표준화 값)*표준오차, 신뢰구간 95% -> z=1.96

#### 평균의 구간추정
Q. 100명 조사 결과 월 용돈 30만원. 표준편차 20만원 신뢰수준을 95%로 하여 모평균의 신뢰구간을 구하라<br>
A. 30 +- 1.96*(20/root 100)

#### 비율의 구간추정
Q. 400명 여론조사해 200명이 찬성. 95%의 신뢰구간<br>
A. 1/2 +- 1.96 * root(0.5*0.5/400)

#### 두 모집단 사이의 구간추정
Q. 연구소에서 2개 회사에서 제작된 전구를 각각 100개씩 구입해 수명을 조사했다.<br>
A사 평균 2300시간,표준편차 64시간<br>
B사 평균 2200시간,표준편차 84시간<br>
평균수명의 차는 어느정도인지 95% 신뢰도로 구간을 추정해라<br>
A. (2300-2200) +- 1.96 * root(64**2/100 + 84**2/100) : 100번중 95번은 평균수명의 차가 79~120시간에서 나타날거다.

Q.취업률 파악을 위해 상경계 400명, 이공계 100명을 각각 조사해 상경계 60% 이공계 50%가 취업.<br>
취업률 차이의 95% 신뢰구간을 추정하시오<br>
A. (0.6-0.5) +- 1.96 * root(0.6*0.4/400+0.5*0.5/100) : 100번중 95번은 -0.008~0.2% 구간 내로 차이가 나타날거다.

#### 대응 모집단 차이의 구간추정: 동일한 집단의 두 변수의 차이를 추정
Q. 100명 대상 6개월간 교육. 교육 받기 전 100명의 평균 영업매출액은 300만원, 교육 후 평균 영업매출액은 320만원. 교육 전후 매출 표준편차 20만원. 신뢰수준 95%<br>
A. (300-320) +- 1.96*20/root 100

### 가설검정: 모집단에 대한 가설을 검정하는 분석방법
귀무가설: 차이가 없다, 효과 없다를 주장
- ~없다로 표현
- a와 b간에 차이가 없다를 기준으로 설정하고 가설검정 수행
- 차이가 없다면 귀무가설 채택, 크다면 대립가설을 채택
- 검정 통계량: 귀무가설과 실제현상인 통계량과 차이가 얼마나 나는가

대립가설: 차이가 있다, 효과 있다 주장, 대립가설 받아들여지면 통계적으로 유의하다
- ~있다로 표현

유의확률
- 표본의 차이가 오차를 감안해도 확실히 크다면 통계적으로 유의하다

제 1종 오류: 귀무가설이 옳은데도 이를 기각하는 오류
제 2종 오류: 귀무가설이 옳지 않은데도 이를 채택하는 오류


#31 스케일러 (변수변환1)
변수 변환: 수집된 데이터를 분석에 필요한 형태로 변환
 스케일 변환, 범주-연속 변환

변수변환
1. 스케일링(Min-Max, Z-score,robust)
2. 구간화
3. 더미변수
4. 함수변환

스케일링
- Min-Max Scaler : y= x-최소 / 최대/최소 (0에서 1로 변환), 이상치 영향 받음
- z-score : z=x-m / 시그마, 이상치 탐지에 유리
- robust : 4분위 편차, 이상치 탐지에 유리, median으로부터 몇 iqr

#31 구간화, 더미변수 (변수변환2)
구간화(Binning)
- 연속형 변수 -> 범주형 변수
- 데이터를 구간별로 구분해서 category 만듦
- ex) 나이 -> 10대, 20대, 30대   점수 -> 수,우,미,양,가

더미변수 pd.get_dummies
- 범주형-> 숫자로 변환
- 데이터 모델링에서는 문자 변수 인식x
- 0과 1 사이의 데이터로 변환
