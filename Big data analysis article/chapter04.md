# 4. 빅데이터 결과해석
## 4.1 분석 모형 평가 및 개선
### (1) 평가지표
#### 분류의 평가지표
1. 오차행렬(confusion matrix)
- 이진, 다중 범주형 레이블의 하위 범주를 세부적으로 살펴보면서 일치 혹은 오류를 파악할 수 있는 결과
- 민감도: 실제 참인 것 중 모델이 참이라고 예측
- 특이도: 실제 거짓인 것 중 모델이 거짓이라고 예측
- 정밀도: 모델이 참이라고 예측한 것 중 실제 참
- F1 Score
2. Roc 곡선
- 가로축을 거짓긍정률, 세로축을 참긍정률로 이진분류의 성능평가에 활용
- 좌상단으로 붙어있는 커브일수록 좋은 이진 분류기
- Roc 곡선 아래 면적이 1에 가까울수록 우수한 성능, 0.5에 가까울수록 나쁜 성능

#### 회귀의 평가지표
- 종속변수가 연속형인 회귀분석류 모델에서는 셀제값과 예측값의 일치정도를 계산해 평가
- SSE
- AE
- MSE
- MAE
- RMSE
- MAPE

### (2) 분석 모형 진단
- 분석에서 충족되어야 할 가정이 있는 모델에서 수행
- 선형회귀모형에서 모형 진단이 필수적으로 필요
#### 정규성 진단
- 오차가 정규분포를 이루고 평균 0이여야함
- 잔차의 히스토그램은 정규분포 모양, p-p 도표는 직선에 일치하면 정규성을 띈다
- H0: 정규분포와 표본분포는 같다, H0: 정규분포와 표본분포는 다르다

#### 등분산성 진단
- 등분산: 독립변수의 구간에서 종속변수의 오차의 분산은 동일해야 한다, 평균을 중심으로 자료의 퍼짐은 크게 다르지 않다
- 잔차도를 그렸을때 자료의 퍼짐 양상이 무작위이면 등분산성에 문제가 없다

#### 독립성 진단
- 독립성: 독립변수가 다르면 종속변수에 대한 오차는 서로 상관이 없고 독립적이여야 한다
- Durbin-Watson 검정방법: 잔차의 자기상관을 검정, 0~4 사이, 2에 가까울수록 자기상관 문제

### (3) 교차검증
- 결과의 일반화 성능비교를 위해 훈련데이터와 테스트데이터로 구분하는 것은 머신러닝 기본 과정
- 교차검증 : 훈련 데이터를 여러 개로 나눌 것인가
- 장점: 특정 평가 데이터 셋에 overfit 되는 것 방지, 정확도 향상, 데이터 부족으로 인한 underfitting 방지
- 단점: 모델 훈련/평가 시간 오래 걸림

1. 홀드아웃 방법
- 주어진 train set을 임의의 비율로 train set과 test set으로 분할해 사용, 9:1,7:3 자주 사용
- 계산 시간 부담 적음

2. k-겹 교차 검증
- 데이터를 k개의 데이터 셋으로 분할, test set을 각각 다르게 하여 총 k개의 데이터 폴드 세트를 구성
- k번 분석 필요, 평균으로 최종 결과 도출

3. 리브-p-아웃 교차 검증
- 전체 데이터중에서 p개의 샘플을 선택
- 평균으로 최종 결과 도출
- 계산 시간 부담 큼

4. 리브-원-아웃 교차 검증
- 3 방법에서 p가 1일때
- 계산 부담 줄어듦, 좋은 결과 얻을 수 있음
- 검증에 사용되는 데이터가 하나이기 때문에, 나머지 데이터를 모델 훈련에 사용할 수 있다
5. 계층별 k-겹 교차 검중
- 종속변수의 분포가 각 클래스별로 불균형을 이룰 때 사용

### (4) 모수 유의성 검정
- 귀무가설(H0): 표본집단의 평균은 모집단과 다르지 않다
- 대립가설(H1): 표본집단의 평균은 모집단과 다르다
- 단일 모집단 검정 통계량 z: 표본 평균-모집단 평균 / 표준오차
- 두 모집단 검정 통계량 z: 두 집단의 평균 차이 / root(두 집단 표준편차 합)
- 대응 모집단 검정 통계량 z: 두 변수의 차이 / root(표준편차**2 / 개수)

#### 교차분석
- 관측빈도와 기대빈도의 교차표를 비교
- 자유도 n-1 * m-1
- 대립가설 : 검정통계량>임계치

#### 분산분석
- 3 집단 이상에서 차이를 검정
- p.487 참고

#### 상관 관계 분석
1. 1단계: 귀무가설 - 변수 간 상관관계 없다
2. 2단계: 검정통계량 계산
3. 3단계: 가설의 기각 및 채택 - t값이 임계치보다 작으면 귀무가설 채택

#### 선형 회귀 분석
- 표준화계수 크기가 클수록 큰 영향 변수
- 자세한 부분은 p.491 참고

### (5) 적합도 검정
- 카이제곱 검정 활용
- x제곱이 작을수록 일치
- df(자유도): 클수록 변수 많고 복잡

### (1) 과대 적합 방지
과대적합: 훈련 데이터에는 성능이 좋으나 테스트 데이터에는 예측,분류 성능이 떨어짐

#### 머신 러닝에서 과대 적합 방지
1. 데이터 증식
2. 가중치 감소
- 개별 가중치의 절대값을 0에 가깝게
- 라소회귀: 절대값
- 릿지회귀: 이상치,노이즈 있는 데이터에 적합, 제곱의 합

#### 딥러닝에서 과대 적합 방지
1. 드롭아웃
- 뉴런 많은 깊은 신경망에서 일부 가중치의 연결을 삭제
2. 가중치 초기화
3. 조기종료: 성능이 나빠지기 시작할 때 훈련을 중지


### (3) 분석모형 융합
1. 배깅
2. 부스팅
3. 스태킹
4. 랜덤포레스트
5. 
